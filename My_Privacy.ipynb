{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "A notebook demonstrating how to anonymise data prior to querying a third party LLM.\n",
        "\n",
        "Sections:\n",
        "    1. Anonymization using Presidio(pattern matching and Named Entity Extraction)\n",
        "    2. Anonymization using Phi-3 (local model with structured generation)"
      ],
      "metadata": {
        "id": "PoEFU5TTmVZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Presidio Anonymization\n",
        "  - Direct matching\n",
        "  - Context matching(spaCy)\n",
        "  - ..."
      ],
      "metadata": {
        "id": "_ZWM3CeGmrlc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai -q\n",
        "!pip install \"presidio_analyzer[transformers]\"\n",
        "!pip install presidio_anonymizer -q\n",
        "!oython -m spacy download en_core_web_lg - q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S998utiKnF2A",
        "outputId": "a02b3b7e-1719-4480-9c36-aa4d9cc176ad"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.7/320.7 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting presidio_analyzer[transformers]\n",
            "  Downloading presidio_analyzer-2.2.354-py3-none-any.whl (92 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.2/92.2 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<4.0.0,>=3.4.4 in /usr/local/lib/python3.10/dist-packages (from presidio_analyzer[transformers]) (3.7.4)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from presidio_analyzer[transformers]) (2024.5.15)\n",
            "Collecting tldextract (from presidio_analyzer[transformers])\n",
            "  Downloading tldextract-5.1.2-py3-none-any.whl (97 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m97.6/97.6 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from presidio_analyzer[transformers]) (6.0.1)\n",
            "Collecting phonenumbers<9.0.0,>=8.12 (from presidio_analyzer[transformers])\n",
            "  Downloading phonenumbers-8.13.37-py2.py3-none-any.whl (2.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.6/2.6 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting spacy-huggingface-pipelines (from presidio_analyzer[transformers])\n",
            "  Downloading spacy_huggingface_pipelines-0.0.4-py2.py3-none-any.whl (11 kB)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (2.7.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (1.25.2)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy-huggingface-pipelines->presidio_analyzer[transformers]) (4.41.1)\n",
            "Requirement already satisfied: torch>=1.8.0 in /usr/local/lib/python3.10/dist-packages (from spacy-huggingface-pipelines->presidio_analyzer[transformers]) (2.3.0+cu121)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from tldextract->presidio_analyzer[transformers]) (3.7)\n",
            "Collecting requests-file>=1.4 (from tldextract->presidio_analyzer[transformers])\n",
            "  Downloading requests_file-2.1.0-py2.py3-none-any.whl (4.2 kB)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /usr/local/lib/python3.10/dist-packages (from tldextract->presidio_analyzer[transformers]) (3.14.0)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (0.1.4)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers]) (3.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers]) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers])\n",
            "  Using cached nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.1.105 (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers])\n",
            "  Using cached nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.1.105 (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers])\n",
            "  Using cached nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "Collecting nvidia-cudnn-cu12==8.9.2.26 (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers])\n",
            "  Using cached nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "Collecting nvidia-cublas-cu12==12.1.3.1 (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers])\n",
            "  Using cached nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "Collecting nvidia-cufft-cu12==11.0.2.54 (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers])\n",
            "  Using cached nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "Collecting nvidia-curand-cu12==10.3.2.106 (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers])\n",
            "  Using cached nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "Collecting nvidia-cusolver-cu12==11.4.5.107 (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers])\n",
            "  Using cached nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "Collecting nvidia-cusparse-cu12==12.1.0.106 (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers])\n",
            "  Using cached nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "Collecting nvidia-nccl-cu12==2.20.5 (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers])\n",
            "  Using cached nvidia_nccl_cu12-2.20.5-py3-none-manylinux2014_x86_64.whl (176.2 MB)\n",
            "Collecting nvidia-nvtx-cu12==12.1.105 (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers])\n",
            "  Using cached nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "Requirement already satisfied: triton==2.3.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers]) (2.3.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers])\n",
            "  Downloading nvidia_nvjitlink_cu12-12.5.40-py3-none-manylinux2014_x86_64.whl (21.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.3/21.3 MB\u001b[0m \u001b[31m39.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.28.0->spacy-huggingface-pipelines->presidio_analyzer[transformers]) (0.23.1)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.28.0->spacy-huggingface-pipelines->presidio_analyzer[transformers]) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<5.0.0,>=4.28.0->spacy-huggingface-pipelines->presidio_analyzer[transformers]) (0.4.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<4.0.0,>=3.4.4->presidio_analyzer[transformers]) (1.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.8.0->spacy-huggingface-pipelines->presidio_analyzer[transformers]) (1.3.0)\n",
            "Installing collected packages: phonenumbers, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, requests-file, nvidia-cusparse-cu12, nvidia-cudnn-cu12, tldextract, nvidia-cusolver-cu12, spacy-huggingface-pipelines, presidio_analyzer\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.20.5 nvidia-nvjitlink-cu12-12.5.40 nvidia-nvtx-cu12-12.1.105 phonenumbers-8.13.37 presidio_analyzer-2.2.354 requests-file-2.1.0 spacy-huggingface-pipelines-0.0.4 tldextract-5.1.2\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h/bin/bash: line 1: oython: command not found\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "simple_text = \"Jane's email is jane.doe@example.com and her birthday is 1992-05-15.\""
      ],
      "metadata": {
        "id": "cnH9diBqnc1E"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from presidio_analyzer import AnalyzerEngine\n",
        "\n",
        "  ## Notes:\n",
        "  # This will use a large spacy model by default: en_core_web_lg\n",
        "\n",
        "  # Set up the engine, loads the NLP module (spaCy model by default) and other PII recognizers\n",
        "analyzer = AnalyzerEngine()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_uo8PiMnm0S",
        "outputId": "cc54feee-0a7e-4176-9dcc-14532103b70f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:configuration file /usr/local/lib/python3.10/dist-packages/conf/default.yaml not found.  Using default config: {'nlp_engine_name': 'spacy', 'models': [{'lang_code': 'en', 'model_name': 'en_core_web_lg'}]}.\n",
            "WARNING:presidio-analyzer:configuration file is missing 'ner_model_configuration'. Using default\n",
            "WARNING:presidio-analyzer:model_to_presidio_entity_mapping is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:low_score_entity_names is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:labels_to_ignore is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:Model en_core_web_lg is not installed. Downloading...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_lg')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Call analyzer to get results\n",
        "simple_analyser_results = analyzer.analyze(text=simple_text,\n",
        "                                          #  entities=[\"EMAIL_ADDRESS\"],\n",
        "                                           language=\"en\")\n",
        "print(f\"\\n\\n{simple_analyser_results}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "az8rmtRCoETv",
        "outputId": "bcfd4e2f-343d-401b-a659-d88407d609cf"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "[type: EMAIL_ADDRESS, start: 16, end: 36, score: 1.0, type: DATE_TIME, start: 57, end: 67, score: 0.95, type: PERSON, start: 0, end: 4, score: 0.85, type: URL, start: 16, end: 23, score: 0.5, type: URL, start: 25, end: 36, score: 0.5]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from presidio_anonymizer import AnonymizerEngine\n",
        "from presidio_anonymizer.entities import RecognizerResult\n",
        "\n",
        "engine = AnonymizerEngine()"
      ],
      "metadata": {
        "id": "-xhZcC_UpAVB"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install faker -q"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB-d94EWpNnt",
        "outputId": "220efe6c-ec25-482e-a4a2-037087058ed5"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.8 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/1.8 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.8 MB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m18.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now add some operators, which generates fake data, using the \"faker library\"\n",
        "from faker import Faker\n",
        "from presidio_anonymizer.entities import OperatorConfig\n",
        "\n",
        "fake = Faker()\n",
        "\n",
        "# Create faker function (note that it has to receive a value)\n",
        "def fake_name(x):\n",
        "  Faker.seed(42)\n",
        "  return fake.name()\n",
        "\n",
        "# Create custom operator for the PERSON entity\n",
        "operators = {'PERSON': OperatorConfig(\"custom\", {\"lambda\": fake_name})}"
      ],
      "metadata": {
        "id": "vH8Xu-B_pS20"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Notice below how the name is replaced, although it's the wrong gender, which could cause issues for the LLM with the incorrect pronouns/pronoun\n",
        "references"
      ],
      "metadata": {
        "id": "EnOLK1Uap4EP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Invoke the anonymize function with the text\n",
        "# Operators to get the anonymizaiton output:\n",
        "simple_anon_result = engine.anonymize(\n",
        "    text=simple_text,\n",
        "    analyzer_results=simple_analyser_results,\n",
        "    operators=operators,\n",
        ")\n",
        "print(\"De-identified text\")\n",
        "print(f\"\\n\\n{simple_anon_result}\")\n",
        "print(\"\\nOriginal text\")\n",
        "print(simple_text)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXJ3lHlqqIlL",
        "outputId": "ff493593-ce97-4f37-cbb9-8e6602cae157"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "De-identified text\n",
            "\n",
            "\n",
            "text: Allison Hill's email is <EMAIL_ADDRESS> and her birthday is <DATE_TIME>.\n",
            "items:\n",
            "[\n",
            "    {'start': 60, 'end': 71, 'entity_type': 'DATE_TIME', 'text': '<DATE_TIME>', 'operator': 'replace'},\n",
            "    {'start': 24, 'end': 39, 'entity_type': 'EMAIL_ADDRESS', 'text': '<EMAIL_ADDRESS>', 'operator': 'replace'},\n",
            "    {'start': 0, 'end': 12, 'entity_type': 'PERSON', 'text': 'Allison Hill', 'operator': 'custom'}\n",
            "]\n",
            "\n",
            "\n",
            "Original text\n",
            "Jane's email is jane.doe@example.com and her birthday is 1992-05-15.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reversible Anonymization\n",
        "  - Presidio analyzer\n",
        "  - Custom anonymizer (replacememt)\n",
        "  - Processing via 3rd party end point (openai)\n",
        "  - Custom reversal (replacement back to original)"
      ],
      "metadata": {
        "id": "N4hl0GHVrA_s"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from presidio_analyzer import AnalyzerEngine\n",
        "from faker import Faker\n",
        "from faker.providers import internet, person, date_time\n",
        "import openai"
      ],
      "metadata": {
        "id": "yYEeUYOQvs9M"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fake = Faker(\"en_US\")\n",
        "fake.add_provider(internet)\n",
        "fake.add_provider(person)\n",
        "fake.add_provider(date_time)\n",
        "\n",
        "analyzer = AnalyzerEngine()\n",
        "\n",
        "def anonymize_text(analyzer_results, text_to_anonymize):\n",
        "    \"\"\"Anonymize text using Faker and build a mapping for de-anonymization.\"\"\"\n",
        "    entity_mapping = {}\n",
        "    updated_text = text_to_anonymize  # Use updated_text to avoid modifying the original text\n",
        "\n",
        "    def replace_and_store(entity_type, replacement_func):\n",
        "        nonlocal updated_text  # Reference the non-local variable\n",
        "        for result in analyzer_results:\n",
        "            if result.entity_type == entity_type:\n",
        "                original_value = text_to_anonymize[result.start:result.end]\n",
        "                fake_value = replacement_func()\n",
        "                entity_mapping[fake_value] = original_value\n",
        "\n",
        "                # Replace in the updated_text the real value with the fake value\n",
        "                updated_text = updated_text.replace(original_value, fake_value, 1)\n",
        "        return updated_text\n",
        "\n",
        "    updated_text = replace_and_store(\"EMAIL_ADDRESS\", fake.safe_email)\n",
        "    updated_text = replace_and_store(\"PERSON\", fake.name)\n",
        "    updated_text = replace_and_store(\"DATE_TIME\", lambda: fake.date_time().strftime('%Y-%m-%d'))\n",
        "\n",
        "    return updated_text, entity_mapping\n",
        "\n",
        "# Define de-anonymization function using the mapping\n",
        "def de_anonymize_text(anonymized_text, entity_mapping):\n",
        "    for fake_value, real_value in entity_mapping.items():\n",
        "        anonymized_text = anonymized_text.replace(fake_value, real_value)\n",
        "    return anonymized_text\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qndk6rBGv4ng",
        "outputId": "3fdf93e7-a4a9-4800-b29a-018ec34ea270"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:presidio-analyzer:configuration file /usr/local/lib/python3.10/dist-packages/conf/default.yaml not found.  Using default config: {'nlp_engine_name': 'spacy', 'models': [{'lang_code': 'en', 'model_name': 'en_core_web_lg'}]}.\n",
            "WARNING:presidio-analyzer:configuration file is missing 'ner_model_configuration'. Using default\n",
            "WARNING:presidio-analyzer:model_to_presidio_entity_mapping is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:low_score_entity_names is missing from configuration, using default\n",
            "WARNING:presidio-analyzer:labels_to_ignore is missing from configuration, using default\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize engines and generate fake text\n",
        "text = \"Jane's email is jane.doe@example.com and her birthday is 1992-05-15.\"\n",
        "\n",
        "# Analyze the text\n",
        "# Note that the supported entities are listed here: https://microsoft.github.io/presidio/supported_entities/\n",
        "# Entity detection can involve multiple techniques - including regex, spaCy model (for context), checksums (validating credit card numbers)\n",
        "analyzer_results = analyzer.analyze(\n",
        "    text=text,\n",
        "    entities=[\"EMAIL_ADDRESS\", \"PERSON\", \"DATE_TIME\"],  # comment out for autodetection (but that requires adjusting the denonymization step)\n",
        "    language=\"en\"\n",
        ")\n",
        "\n",
        "# Display the initial text and the analysis results\n",
        "print(f\"Original Text:\\n{text}\\n\")\n",
        "print(f\"Analyzer result:\\n{analyzer_results}\\n\")\n",
        "\n",
        "# Anonymize the text and display the anonymized text and mapping\n",
        "anonymized_text, entity_mapping = anonymize_text(analyzer_results, text)\n",
        "print(f\"Anonymized Text:\\n{anonymized_text}\\n\")\n",
        "print(f\"Entity Mapping:\\n{entity_mapping}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sCDtNhqMCycj",
        "outputId": "6ba7fa0f-31dd-408e-b066-e1bc621c8484"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original Text:\n",
            "Jane's email is jane.doe@example.com and her birthday is 1992-05-15.\n",
            "\n",
            "Analyzer result:\n",
            "[type: EMAIL_ADDRESS, start: 16, end: 36, score: 1.0, type: DATE_TIME, start: 57, end: 67, score: 0.95, type: PERSON, start: 0, end: 4, score: 0.85]\n",
            "\n",
            "Anonymized Text:\n",
            "Sharon James's email is stanleykendra@example.org and her birthday is 1994-09-04.\n",
            "\n",
            "Entity Mapping:\n",
            "{'stanleykendra@example.org': 'jane.doe@example.com', 'Sharon James': 'Jane', '1994-09-04': '1992-05-15'}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "# Prompt for API key in Colab\n",
        "os.environ[\"OPENAI_API_KEY\"] = getpass.getpass(\"Please enter your OpenAI API key: \")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uaAvqxydE2tI",
        "outputId": "c3f91d7d-1710-4fb4-8d27-8ea0be847b24"
      },
      "execution_count": 38,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Please enter your OpenAI API key: ··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate text continuation with GPT-3.5 (using the OpenAI API)\n",
        "# Specify a prompt for GPT-3.5 using the anonymized text\n",
        "prompt = anonymized_text + \" Re-write that information a little differently.\"\n",
        "\n",
        "from openai import OpenAI\n",
        "client = OpenAI()\n",
        "\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": prompt},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "print(response)\n",
        "# Extract the generated text from the response\n",
        "generated_text = response.choices[0].message.content.strip()\n",
        "\n",
        "print(f\"\\nAnonymized Text Sent to LLM:\\n{prompt}\\n\")\n",
        "print(f\"LLM Response:\\n{generated_text}\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eYA8TCItE9hF",
        "outputId": "6bb50baa-f69e-49d8-a096-cbb2b9f0abe8"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-9W18YhdS3I2nyNJGBbTLnWxi7M8Fq', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='Email: stanleykendra@example.org\\nBirthday: September 4, 1994', role='assistant', function_call=None, tool_calls=None))], created=1717417894, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=18, prompt_tokens=39, total_tokens=57))\n",
            "\n",
            "Anonymized Text Sent to LLM:\n",
            "Sharon James's email is stanleykendra@example.org and her birthday is 1994-09-04. Re-write that information a little differently.\n",
            "\n",
            "LLM Response:\n",
            "Email: stanleykendra@example.org\n",
            "Birthday: September 4, 1994\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nAnonymized Text Sent to LLM:\\n{prompt}\\n\")\n",
        "print(f\"\\nLLM Response:\\n{generated_text}\\n\")\n",
        "\n",
        "# De-anonymize the response and display the final result\n",
        "\n",
        "# De-anonymize the full text\n",
        "de_anonymized_text = de_anonymize_text(generated_text, entity_mapping)\n",
        "print(f\"\\nDe-anonymized Response:\\n{de_anonymized_text}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQfqAU18GHYf",
        "outputId": "f8a8c1f2-2484-47e2-bf68-b7b4d9ed5f75"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Anonymized Text Sent to LLM:\n",
            "Sharon James's email is stanleykendra@example.org and her birthday is 1994-09-04. Re-write that information a little differently.\n",
            "\n",
            "\n",
            "LLM Response:\n",
            "Email: stanleykendra@example.org\n",
            "Birthday: September 4, 1994\n",
            "\n",
            "\n",
            "De-anonymized Response:\n",
            "Email: jane.doe@example.com\n",
            "Birthday: September 4, 1994\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the initial text and the analysis results\n",
        "print(f\"\\nOriginal Text:\\n{text}\\n\")\n",
        "print(f\"\\nAnalyzer result:\\n{analyzer_results}\\n\")\n",
        "\n",
        "# Anonymize the text and display the anonymized text and mapping\n",
        "print(f\"\\nAnonymized Text:\\n{anonymized_text}\\n\")\n",
        "print(f\"\\nEntity Mapping:\\n{entity_mapping}\\n\")\n",
        "print(f\"\\nAnonymized Text Sent to LLM:\\n{prompt}\\n\")\n",
        "print(f\"\\nLLM Response:\\n{generated_text}\\n\")\n",
        "print(f\"\\nDe-anonymized Response:\\n{de_anonymized_text}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGWvPeS_Fuy-",
        "outputId": "f29c8fb6-ffa2-49ae-a3ce-f37ea90d8514"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Original Text:\n",
            "Jane's email is jane.doe@example.com and her birthday is 1992-05-15.\n",
            "\n",
            "\n",
            "Analyzer result:\n",
            "[type: EMAIL_ADDRESS, start: 16, end: 36, score: 1.0, type: DATE_TIME, start: 57, end: 67, score: 0.95, type: PERSON, start: 0, end: 4, score: 0.85]\n",
            "\n",
            "\n",
            "Anonymized Text:\n",
            "Sharon James's email is stanleykendra@example.org and her birthday is 1994-09-04.\n",
            "\n",
            "\n",
            "Entity Mapping:\n",
            "{'stanleykendra@example.org': 'jane.doe@example.com', 'Sharon James': 'Jane', '1994-09-04': '1992-05-15'}\n",
            "\n",
            "\n",
            "Anonymized Text Sent to LLM:\n",
            "Sharon James's email is stanleykendra@example.org and her birthday is 1994-09-04. Re-write that information a little differently.\n",
            "\n",
            "\n",
            "LLM Response:\n",
            "Email: stanleykendra@example.org\n",
            "Birthday: September 4, 1994\n",
            "\n",
            "\n",
            "De-anonymized Response:\n",
            "Email: jane.doe@example.com\n",
            "Birthday: September 4, 1994\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Local LLM based Anonymization\n",
        "- Phi-3 with structured generation (from Outlines)."
      ],
      "metadata": {
        "id": "u361o5Udm6QU"
      }
    }
  ]
}